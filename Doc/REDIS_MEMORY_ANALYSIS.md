# Redis Memory Analysis - Is 30MB Enough?

## üìä Memory Usage Calculation

### Per Barcode Cache Entry

Each barcode creates **2-3 cache entries**:

1. **Barcode key** (by barcode value)
2. **Short code key** (by short_code value)  
3. **Status key** (quick status lookup)

### Data Size Per Entry

```python
# Typical barcode cache entry structure:
{
    'id': 12345,                    # 4 bytes (int)
    'barcode': 'FRAM-20240101-001', # ~20 bytes (string)
    'short_code': 'FRAM-001',       # ~10 bytes (string)
    'tag': 'new',                   # ~5 bytes (string)
    'product_id': 100,              # 4 bytes (int)
    'variant_id': None,             # 0 bytes (null)
    'is_primary': False,            # 1 byte (bool)
    'purchase_id': 50,              # 4 bytes (int)
    'purchase_item_id': 200,        # 4 bytes (int)
    'product': {                    # ~150 bytes (nested dict)
        'id': 100,
        'name': 'Product Name...',  # ~30 bytes
        'sku': 'SKU123',            # ~10 bytes
        'is_active': True           # 1 byte
    }
}
```

**Estimated size per entry:**
- Raw data: ~200-250 bytes
- Redis overhead (key names, metadata): ~100-150 bytes
- **Total per entry: ~350-400 bytes**

### Total Memory Calculation

**With 30MB Redis:**

```
30 MB = 30 √ó 1024 √ó 1024 = 31,457,280 bytes

Maximum entries (conservative):
31,457,280 √∑ 400 = ~78,600 entries

With 2-3 entries per barcode:
78,600 √∑ 2.5 = ~31,400 unique barcodes
```

**But wait!** Cache has TTL (Time To Live):
- Barcode data: 10 minutes
- Status cache: 2 minutes
- Lookup cache: 5 minutes

**Active barcodes at any time:**
- Only recently accessed barcodes are cached
- Old entries expire automatically
- Typical active cache: 5,000-15,000 entries

---

## ‚úÖ **30MB is MORE THAN ENOUGH!**

### Why 30MB Works:

1. **TTL Expiration**: Old entries auto-delete
   - Only active/recent barcodes stay in cache
   - You don't need to cache ALL barcodes

2. **Typical Usage**:
   - Active barcodes in cache: 5,000-15,000
   - Memory used: ~5-15 MB
   - **30MB gives you 2-3x headroom**

3. **Real-World Example**:
   ```
   Scenario: 50,000 total barcodes in database
   - Active in cache (last 10 min): ~5,000 barcodes
   - Memory used: ~5 MB
   - Remaining: 25 MB free
   ```

4. **Barcode Search Pattern**:
   - Most searches are for recent/popular barcodes
   - Rare barcodes don't need to be cached
   - Cache naturally keeps "hot" data

---

## üìà Memory Usage Monitoring

### Check Current Usage

**Option 1: Redis CLI (if available)**
```bash
redis-cli INFO memory
# Look for: used_memory_human
```

**Option 2: Django Management Command**
```python
# In Django shell
from django.core.cache import cache
client = cache._cache.get_client()

# Get memory info (if supported)
try:
    info = client.info('memory')
    print(f"Used memory: {info.get('used_memory_human', 'N/A')}")
except:
    print("Memory info not available")
```

**Option 3: Check Cache Entry Count**
```python
# In Django shell
from django.core.cache import cache
from backend.catalog.barcode_cache import get_barcode_cache_key

# Estimate entries (approximate)
# This is a rough estimate
```

---

## üéØ Optimization Tips (If Needed)

### If You Approach 30MB Limit:

1. **Reduce Cache TTL** (in `barcode_cache.py`):
   ```python
   # Current: 10 minutes
   BARCODE_CACHE_TTL = 600  # 10 minutes
   
   # Reduce to 5 minutes
   BARCODE_CACHE_TTL = 300  # 5 minutes
   ```

2. **Reduce MAX_ENTRIES** (in `settings.py`):
   ```python
   'OPTIONS': {
       'MAX_ENTRIES': 5000,  # Instead of 10000
   }
   ```

3. **Cache Only Active Barcodes**:
   - Current implementation already does this
   - Only caches barcodes that are accessed
   - TTL ensures old entries expire

4. **Use Compression** (if Redis supports):
   ```python
   'OPTIONS': {
       'COMPRESSOR': 'django_redis.compressors.zlib.ZlibCompressor',
   }
   ```

---

## üìä Expected Memory Usage

### Conservative Estimate:

| Barcodes in Cache | Memory Used | % of 30MB |
|-------------------|-------------|-----------|
| 5,000 active | ~5 MB | 17% |
| 10,000 active | ~10 MB | 33% |
| 15,000 active | ~15 MB | 50% |
| 20,000 active | ~20 MB | 67% |
| 30,000 active | ~30 MB | 100% |

**Realistic scenario:**
- You'll typically have 5,000-10,000 active barcodes
- Memory usage: 5-10 MB
- **30MB is 3-6x more than you need!**

---

## ‚úÖ **Conclusion: 30MB is Perfect!**

### Why It's Enough:

1. ‚úÖ **TTL expiration** keeps cache size manageable
2. ‚úÖ **Only active barcodes** are cached (not all barcodes)
3. ‚úÖ **Typical usage** is 5-10 MB (well under 30MB)
4. ‚úÖ **2-3x headroom** for traffic spikes
5. ‚úÖ **Barcode data is small** (~400 bytes per entry)

### When You Might Need More:

- ‚ùå If you have 100,000+ active barcodes accessed in 10 minutes
- ‚ùå If you disable TTL expiration
- ‚ùå If you cache entire product catalogs (not just barcodes)

**For barcode-only caching with TTL: 30MB is MORE than sufficient!**

---

## üöÄ Performance Impact

With 30MB Redis:
- ‚úÖ **Fast lookups**: 1-5ms (vs 50-200ms from database)
- ‚úÖ **High hit rate**: 90%+ for active barcodes
- ‚úÖ **Low memory**: Uses only 5-10 MB typically
- ‚úÖ **Auto-cleanup**: TTL removes old entries

**You're all set!** 30MB is perfect for your use case.
